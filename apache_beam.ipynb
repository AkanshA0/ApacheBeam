{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Apache Beam in Colab — End‑to‑End Demo\n*Composite Transform · Pipeline IO · ParDo · Windowing · Map · Filter · Partition · Beam ML (RunInference)*\n\n> Runs on **Google Colab** with the **DirectRunner**."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1) Install & Imports"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "!pip -q install apache-beam==2.56.0 scikit-learn==1.5.2\n\nimport apache_beam as beam\nfrom apache_beam.options.pipeline_options import PipelineOptions\nfrom apache_beam.transforms.window import FixedWindows\nfrom apache_beam.testing.test_stream import TestStream\n\nimport re, os, numpy as np, pandas as pd\nprint(\"Beam version:\", beam.__version__)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2) Hello, Beam — Minimal pipeline"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def run_hello():\n    with beam.Pipeline(options=PipelineOptions()) as p:\n        (p | beam.Create([\"hello\",\"beam\",\"from\",\"colab\"])\n           | beam.Map(lambda s: s.upper())\n           | beam.Map(print))\n\nrun_hello()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3) Pipeline IO — ReadFromText & WriteToText"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "input_path = \"/content/beam_io_input.txt\"\nwith open(input_path, \"w\", encoding=\"utf-8\") as f:\n    f.write(\"\\n\".join([\n        \"Apache Beam makes data processing portable and unified\",\n        \"Map and Filter are element-wise transforms\",\n        \"ParDo runs user code (DoFn) on each element\",\n        \"Windowing groups elements by event time windows\"\n    ]))\n\noutput_prefix = \"/content/beam_io_output\"\n\ndef run_io():\n    with beam.Pipeline(options=PipelineOptions()) as p:\n        lines = p | beam.io.ReadFromText(input_path)\n        words = (lines\n                 | \"Lower\" >> beam.Map(lambda s: s.lower())\n                 | \"Tokens\" >> beam.FlatMap(lambda s: re.findall(r\"[a-z]+\", s)))\n        counts = (words | beam.Map(lambda w: (w,1)) | beam.CombinePerKey(sum))\n        counts | beam.io.WriteToText(output_prefix)\n\nrun_io()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4) Map · Filter · ParDo (DoFn)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "class CleanAndLength(beam.DoFn):\n    def process(self, element: str):\n        for t in re.findall(r\"[a-z]+\", element.lower()):\n            if len(t) >= 4:\n                yield (t, len(t))\n\ndef run_elementwise():\n    data = [\"Beam combines batch and streaming.\",\n            \"ParDo lets you run your own functions.\",\n            \"Filter discards, Map transforms.\"]\n    with beam.Pipeline(options=PipelineOptions()) as p:\n        (p | beam.Create(data)\n           | \"ParDoCleanLen\" >> beam.ParDo(CleanAndLength())\n           | \"FilterLen>=5\" >> beam.Filter(lambda kv: kv[1] >= 5)\n           | \"Fmt\" >> beam.Map(lambda kv: f\"{kv[0]}:{kv[1]}\")\n           | beam.Map(print))\n\nrun_elementwise()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5) Composite Transform (PTransform)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "class CleanTokenizeCount(beam.PTransform):\n    def expand(self, pcoll):\n        return (pcoll\n                | beam.Map(lambda s: s.lower())\n                | beam.FlatMap(lambda s: re.findall(r\"[a-z]+\", s))\n                | beam.Map(lambda w: (w,1))\n                | beam.CombinePerKey(sum))\n\ndef run_composite():\n    data = [\"Composite transforms encapsulate reusable logic.\",\n            \"Encapsulation makes pipelines cleaner.\"]\n    with beam.Pipeline(options=PipelineOptions()) as p:\n        (p | beam.Create(data) | CleanTokenizeCount() | beam.Map(print))\n\nrun_composite()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6) Partition — split a PCollection into multiple PCollections"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def part_fn(x, n):\n    return 0 if x < 0 else (1 if x == 0 else 2)\n\ndef run_partition():\n    nums = list(range(-5,6))\n    with beam.Pipeline(options=PipelineOptions()) as p:\n        neg, zero, pos = (p | beam.Create(nums)) | beam.Partition(part_fn, 3)\n        neg  | \"PrintNeg\"  >> beam.Map(lambda x: (\"neg\", x))  | beam.Map(print)\n        zero | \"PrintZero\" >> beam.Map(lambda x: (\"zero\", x)) | beam.Map(print)\n        pos  | \"PrintPos\"  >> beam.Map(lambda x: (\"pos\", x))  | beam.Map(print)\n\nrun_partition()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7) Windowing — Fixed windows with TestStream (event time)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def run_windowing():\n    start = beam.timestamp.Timestamp(0)\n    ts = (TestStream()\n          .add_elements([beam.window.TimestampedValue(1, start + 0)])\n          .advance_watermark_to(start + 5)\n          .add_elements([beam.window.TimestampedValue(2, start + 6),\n                         beam.window.TimestampedValue(3, start + 7)])\n          .advance_watermark_to_infinity())\n\n    with beam.Pipeline(options=PipelineOptions()) as p:\n        (p | ts\n           | \"Win5s\" >> beam.WindowInto(FixedWindows(5))\n           | \"Sum\" >> beam.CombineGlobally(sum).without_defaults()\n           | beam.Map(print))\n\nrun_windowing()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 8) Beam‑ML — RunInference with scikit‑learn (Iris)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline as SkPipeline\nimport joblib\n\niris = load_iris(as_frame=True)\nX_train, X_test, y_train, y_test = train_test_split(\n    iris.data, iris.target, test_size=0.25, random_state=42, stratify=iris.target\n)\nsk_model = SkPipeline([('scaler', StandardScaler()), ('lr', LogisticRegression(max_iter=500))])\nsk_model.fit(X_train, y_train)\nprint(\"Local sklearn accuracy:\", sk_model.score(X_test, y_test))\n\nmodel_path = \"/content/iris_lr.joblib\"\njoblib.dump(sk_model, model_path)\nprint(\"Saved:\", model_path)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from apache_beam.ml.inference.base import RunInference\nfrom apache_beam.ml.inference.sklearn_inference import SklearnModelHandlerNumpy\n\ndef run_inference_with_beam():\n    handler = SklearnModelHandlerNumpy(model_uri=\"/content/iris_lr.joblib\")\n    data = iris.data.to_numpy().tolist()[:10]\n    with beam.Pipeline(options=PipelineOptions()) as p:\n        (p | beam.Create(data)\n           | beam.Map(lambda row: np.array(row, dtype=float))\n           | \"Infer\" >> RunInference(handler)\n           | beam.Map(lambda pred: int(np.argmax(pred.inference)))\n           | beam.Map(print))\n\nrun_inference_with_beam()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 9) What to record for your video\n- Show **Hello, Beam** running\n- Show **IO** read & write shards\n- **Map/Filter/ParDo** outputs\n- **Composite Transform** in action\n- **Partition** results for (neg, zero, pos)\n- **Windowing** with 5s windows\n- **RunInference** predictions from the sklearn model"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}